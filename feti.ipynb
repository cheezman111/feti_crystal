{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase                        import Atoms\n",
    "from ase.visualize              import view\n",
    "import matplotlib.pyplot            as plt\n",
    "import graphdot.kernel.molecular    as gkern\n",
    "import graphdot\n",
    "import seaborn                      as sns\n",
    "import numpy                        as np\n",
    "import timeit\n",
    "import pandas                       as pd\n",
    "import scipy\n",
    "import sklearn.linear_model\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from feti_filtered.dat\n",
    "positions = []\n",
    "forces = []\n",
    "\n",
    "with open('feti_filtered.dat') as feti:\n",
    "    for line in feti:\n",
    "        parts = line.split()\n",
    "        if len(parts) == 3:\n",
    "            positions.append([])\n",
    "            forces.append([])\n",
    "        if len(parts) == 6:\n",
    "            parts_floats = [float(x) for x in parts]\n",
    "            positions[-1].append(parts_floats[:3])\n",
    "            forces[-1].append(parts_floats[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce graphs\n",
    "graphs = []\n",
    "symbols = 'Fe'*64 + 'Ti'*64\n",
    "for position_step in positions:\n",
    "    atoms = Atoms(symbols, position_step, pbc=True)\n",
    "    graphs.append(graphdot.Graph.from_ase(atoms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_to_k_sim(nu, lambda_h):\n",
    "    zeta = 1\n",
    "    s = 1\n",
    "    # try higher q for shorter mean path lengths\n",
    "    q = .2\n",
    "    # use kernel from atomization paper\n",
    "    tang_kernel = gkern.Tang2019MolecularKernel(\n",
    "                        stopping_probability=q,\n",
    "                        starting_probability=lambda x, y: s,\n",
    "                        element_prior=nu,\n",
    "                        edge_length_scale=lambda_h)\n",
    "    k = tang_kernel(graphs[:50])\n",
    "    d = np.diag(k)**-0.5\n",
    "    k_sim = np.diag(d).dot(k).dot(np.diag(d))\n",
    "    \n",
    "    return k_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_sim_to_variance(k_sim):\n",
    "    flat = k_sim.flatten()\n",
    "    return np.var(flat)\n",
    "\n",
    "def k_sim_to_mean(k_sim):\n",
    "    flat = k_sim.flatten()\n",
    "    return np.mean(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_s     = np.array([.01,.05,.1,5,.99])\n",
    "lambda_s = np.array([.01,.05,.1,.5,1])\n",
    "\n",
    "k_sim_matrix = []\n",
    "var_matrix = []\n",
    "mean_matrix=[]\n",
    "for nu in nu_s:\n",
    "    k_sim_matrix.append([])\n",
    "    var_matrix.append([])\n",
    "    mean_matrix.append([])\n",
    "    for lambda_h in lambda_s:\n",
    "        k_sim = hyper_to_k_sim(nu, lambda_h)\n",
    "        k_sim_matrix[-1].append(k_sim)\n",
    "        flat = k_sim.flatten()\n",
    "        var = np.var(flat)\n",
    "        var_matrix[-1].append(var)\n",
    "        mean= np.mean(flat)\n",
    "        mean_matrix[-1].append(mean)\n",
    "        \n",
    "sns.heatmap(mean_matrix, square=True,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.Series(k_sim_matrix[2][2].flatten()).plot(kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-np.array(mean_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = k_sim.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(flat).plot(kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(1-flat).plot(kind='hist', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.gamma.fit(1-flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,.006,100)\n",
    "plt.plot(x, scipy.stats.gamma.pdf(x, 0.9094693984,loc=0, scale = 0.0010062714))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = scipy.stats.gamma(12.8834, loc=0.99389, scale = 0.0039007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular points from gamma at .994 to gamma at 1\n",
    "x = np.linspace(.99,1.5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, scipy.stats.gamma.pdf(x, 12.8834,loc=.99389, scale = 0.0039007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.gamma(a=5,loc=2, scale = 3).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,1000)\n",
    "plt.plot(x, scipy.stats.gamma.pdf(x, 5, loc=4, scale=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(flat,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partials(hypers, mean0, beta):\n",
    "    partial_derivatives = []       \n",
    "    for i, hyper_value in enumerate(hypers):\n",
    "        delta_hyper = hyper_value/beta\n",
    "        \n",
    "        hypers1 = hypers.copy()\n",
    "        hypers1[i] += delta_hyper\n",
    "        k_sim1 = hyper_to_k_sim(*hypers1)\n",
    "        mean1  = k_sim_to_mean(k_sim1)\n",
    "\n",
    "        change_in_mean = mean1-mean0\n",
    "\n",
    "        partial_derivatives.append(change_in_mean/delta_hyper)\n",
    "    return partial_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypers:    [0.3, 0.1]\n",
      "Mean:      0.9997394233454997\n",
      "Partials:  [0.00016993842788526337, 0.0015096914496304237]\n",
      "Hypers:    [0.29830061572114736, 0.08490308550369577]\n",
      "Mean:      0.9997153003861015\n",
      "Partials:  [0.00017895404476435487, 0.0016076624499031813]\n",
      "Hypers:    [0.2965110752735038, 0.06882646100466396]\n",
      "Mean:      0.9996881325786813\n",
      "Partials:  [0.0001904775636047991, 0.00170800341691216]\n",
      "Hypers:    [0.29460629963745577, 0.051746426835542356]\n",
      "Mean:      0.9996562876466087\n",
      "Partials:  [0.00021038866459032667, 0.002005848950495389]\n",
      "Hypers:    [0.2925024129915525, 0.031687937330588466]\n",
      "Mean:      0.9996075941420437\n",
      "Partials:  [0.00023352447341865615, 0.0029450183949473936]\n",
      "Hypers:    [0.29016716825736594, 0.002237753381114531]\n",
      "Mean:      0.9995006652825931\n",
      "Partials:  [0.00028324907347860093, 0.003155554825350506]\n",
      "Hypers:    [0.2873346775225799, -0.02931779487239053]\n",
      "Mean:      0.9995990502553819\n",
      "Partials:  [0.0002490275607258972, -0.0032045292379784813]\n",
      "Hypers:    [0.28484440191532095, 0.0027274975073942817]\n",
      "Mean:      0.9995010001017414\n",
      "Partials:  [0.00029062869384868724, 0.003852565175746304]\n",
      "Hypers:    [0.2819381149768341, -0.035798154250068756]\n",
      "Mean:      0.999616765354179\n",
      "Partials:  [0.00024012893405202593, -0.0027496903757808105]\n",
      "Hypers:    [0.2795368256363138, -0.008301250492260652]\n",
      "Mean:      0.9995195655562725\n",
      "Partials:  [0.0002905291455593459, -0.003791705642605867]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Ascent to find set of hyperparameters which \n",
    "# maximize the dissimilarity of the normalized k matrix\n",
    "\n",
    "# starting point\n",
    "# legend: [nu, lambda]\n",
    "hypers = [.3, .1]\n",
    "\n",
    "alpha = 10\n",
    "beta = 100\n",
    "for iteration in range(10):\n",
    "    print('Hypers:   ', hypers)\n",
    "\n",
    "    # calculate \n",
    "    k_sim0 = hyper_to_k_sim(*hypers)\n",
    "    mean0  = k_sim_to_mean(k_sim0)\n",
    "    print('Mean:     ', mean0)\n",
    "    \n",
    "    # produce partial derivatives:\n",
    "    partial_derivatives = get_partials(hypers, mean0, beta)\n",
    "    print('Partials: ', partial_derivatives)\n",
    "    \n",
    "    # update hypers\n",
    "    hypers = list(map( (lambda hyp,part:hyp-alpha*part), hypers, partial_derivatives))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = [.3, .1]\n",
    "k_sim_0 = hyper_to_k_sim(*hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30170642506421474, 0.11520199988447324]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_hypers = map(lambda x,y:x+10*y, hypers, partial_derivatives)\n",
    "list(new_hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5a5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphdot.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
